This notebook presents the fine-tuning of a GPT-2 language model to generate Persian poetry inspired by Ferdowsi, the great classical Persian poet.
Using PyTorch and Hugging Face Transformers, the model is trained on a poetry corpus to learn stylistic and linguistic patterns characteristic of Ferdowsiâ€™s works.
The notebook covers data preprocessing, tokenization, train/test splitting, model fine-tuning, and poem generation on unseen prompts.
